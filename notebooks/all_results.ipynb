{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio raíz del proyecto a sys.path\n",
    "project_root = \"/home/javitrucas/TFG\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scripts.dataset_loader import load_dataset\n",
    "from scripts.medical_scripts.medical_evaluation import ModelEvaluator\n",
    "from scripts.medical_scripts.medical_training import Training\n",
    "from scripts.MIL_utils import MIL_collate_fn\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from box import Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config):\n",
    "    # Crear un objeto temporal para compatibilidad\n",
    "    class TempConfig:\n",
    "        def __init__(self, config_dict):\n",
    "            self.__dict__.update(config_dict)\n",
    "\n",
    "    config_obj = TempConfig(config)\n",
    "\n",
    "    # Iniciar wandb\n",
    "    wandb.init(\n",
    "        project=\"TFG\",\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    # Parámetros controlados desde la configuración\n",
    "    dataset_name = config_obj.dataset_name\n",
    "    num_epochs = config_obj.num_epochs\n",
    "    learning_rate = config_obj.learning_rate\n",
    "    batch_size = config_obj.batch_size\n",
    "    pooling_type = config_obj.pooling_type       \n",
    "    input_feature_dim = config_obj.input_feature_dim\n",
    "    feature_dim = config_obj.feature_dim\n",
    "\n",
    "    # Directorio para guardar modelos\n",
    "    output_model_dir = f\"./models/{dataset_name.split('-')[0]}\"\n",
    "    os.makedirs(output_model_dir, exist_ok=True)\n",
    "\n",
    "    # Cargar datasets\n",
    "    train_dataset, val_dataset = load_dataset(config=config, mode=\"train_val\")\n",
    "    test_dataset = load_dataset(config=config, mode=\"test\")\n",
    "\n",
    "    # Crear dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=MIL_collate_fn)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=MIL_collate_fn)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=MIL_collate_fn)\n",
    "\n",
    "    # Iniciar el entrenamiento\n",
    "    trainer = Training(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        output_model_dir=output_model_dir,\n",
    "        pooling_type=pooling_type,              # Pasar pooling_type\n",
    "        input_feature_dim=input_feature_dim,    # Pasar input_feature_dim\n",
    "        feature_dim=feature_dim,                # Pasar feature_dim\n",
    "        wandb=wandb\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Guardar el modelo correctamente antes de evaluarlo\n",
    "    model_path = os.path.join(output_model_dir, 'model.pth')\n",
    "    torch.save(trainer.model.state_dict(), model_path)  # Asegurar que el modelo se guarda\n",
    "\n",
    "    # Verificar que el archivo se haya guardado correctamente\n",
    "    if not os.path.isfile(model_path):\n",
    "        raise ValueError(f\"El modelo no se guardó correctamente en: {model_path}\")\n",
    "\n",
    "    # Guardar el modelo como un artefacto en wandb\n",
    "    artifact = wandb.Artifact('model', type='model')\n",
    "    artifact.add_file(model_path)\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    # Iniciar la evaluación\n",
    "    evaluator = ModelEvaluator(\n",
    "        model_path=model_path,\n",
    "        test_loader=test_loader,\n",
    "        batch_size=batch_size,\n",
    "        input_feature_dim=input_feature_dim,  \n",
    "        feature_dim=feature_dim,              \n",
    "        pooling_type=pooling_type,\n",
    "        wandb=wandb\n",
    "    )\n",
    "    # Iniciar la evaluación\n",
    "    metrics, attention_weights_list = evaluator.evaluate()  # Se desempaquetan correctamente los valores\n",
    "\n",
    "    # Métricas incluidas\n",
    "    results = {\n",
    "        \"train_loss_curve\": trainer.train_loss_curve,\n",
    "        \"val_loss_curve\": trainer.val_loss_curve,\n",
    "        \"train_accuracy_curve\": trainer.train_accuracy_curve,\n",
    "        \"val_accuracy_curve\": trainer.val_accuracy_curve,\n",
    "        \"test_loss_curve\": evaluator.test_loss_curve,\n",
    "        \"test_accuracy_curve\": evaluator.test_accuracy_curve,\n",
    "        \"train_f1_score\": trainer.train_f1_score,\n",
    "        \"val_f1_score\": trainer.val_f1_score,\n",
    "        \"test_f1_score\": evaluator.test_f1_score,\n",
    "        \"train_auc_roc\": trainer.train_auc_roc,\n",
    "        \"val_auc_roc\": trainer.val_auc_roc,\n",
    "        \"test_auc_roc\": evaluator.test_auc_roc,\n",
    "        \"train_precision\": trainer.train_precision,\n",
    "        \"val_precision\": trainer.val_precision,\n",
    "        \"test_precision\": evaluator.test_precision,\n",
    "        \"train_recall\": trainer.train_recall,\n",
    "        \"val_recall\": trainer.val_recall,\n",
    "        \"test_recall\": evaluator.test_recall,\n",
    "        \"confusion_matrix\": metrics[\"confusion_matrix\"]  # Se accede correctamente a metrics\n",
    "    }\n",
    "\n",
    "    # Finalizar wandb\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavitrucas\u001b[0m (\u001b[33mjavitrucas-universidad-de-granada\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javitrucas/TFG/notebooks/wandb/run-20250418_111257-ijcv4ma3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/ijcv4ma3' target=\"_blank\">faithful-bird-156</a></strong> to <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG' target=\"_blank\">https://wandb.ai/javitrucas-universidad-de-granada/TFG</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/ijcv4ma3' target=\"_blank\">https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/ijcv4ma3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsna\n",
      "[RSNADataset] Scanning files...\n",
      "[RSNADataset] Found 1000 already processed bags\n",
      "[RSNADataset] Number of bags found: 1000\n",
      "rsna\n",
      "[RSNADataset] Scanning files...\n",
      "[RSNADataset] Found 150 already processed bags\n",
      "[RSNADataset] Number of bags found: 150\n",
      "Epoch 1/50\n",
      "Train - Loss: 0.7003, Acc: 0.6162, AUC: 0.6278, F1: 0.4770\n",
      "Val   - Loss: 0.5861, Acc: 0.6950, AUC: 0.7532, F1: 0.5197\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 2/50\n",
      "Train - Loss: 0.6071, Acc: 0.6987, AUC: 0.7340, F1: 0.6043\n",
      "Val   - Loss: 0.8087, Acc: 0.5000, AUC: 0.7801, F1: 0.6124\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 3/50\n",
      "Train - Loss: 0.6058, Acc: 0.6900, AUC: 0.7526, F1: 0.5948\n",
      "Val   - Loss: 0.5291, Acc: 0.7200, AUC: 0.8012, F1: 0.6410\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 4/50\n",
      "Train - Loss: 0.5469, Acc: 0.7350, AUC: 0.7873, F1: 0.6570\n",
      "Val   - Loss: 0.9158, Acc: 0.6350, AUC: 0.8065, F1: 0.1978\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 5/50\n",
      "Train - Loss: 0.5229, Acc: 0.7500, AUC: 0.8188, F1: 0.6795\n",
      "Val   - Loss: 0.8364, Acc: 0.5750, AUC: 0.7770, F1: 0.6473\n",
      "Epoch 6/50\n",
      "Train - Loss: 0.5271, Acc: 0.7512, AUC: 0.8150, F1: 0.6806\n",
      "Val   - Loss: 0.6756, Acc: 0.6550, AUC: 0.8191, F1: 0.6820\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 7/50\n",
      "Train - Loss: 0.5182, Acc: 0.7388, AUC: 0.8234, F1: 0.6719\n",
      "Val   - Loss: 0.4897, Acc: 0.7750, AUC: 0.8398, F1: 0.7020\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 8/50\n",
      "Train - Loss: 0.5425, Acc: 0.7525, AUC: 0.8059, F1: 0.6906\n",
      "Val   - Loss: 0.5632, Acc: 0.7300, AUC: 0.8064, F1: 0.6087\n",
      "Epoch 9/50\n",
      "Train - Loss: 0.5285, Acc: 0.7650, AUC: 0.8171, F1: 0.7035\n",
      "Val   - Loss: 0.4876, Acc: 0.7800, AUC: 0.8485, F1: 0.7105\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 10/50\n",
      "Train - Loss: 0.4881, Acc: 0.7837, AUC: 0.8429, F1: 0.7250\n",
      "Val   - Loss: 0.4825, Acc: 0.7750, AUC: 0.8466, F1: 0.7020\n",
      "Epoch 11/50\n",
      "Train - Loss: 0.4968, Acc: 0.7925, AUC: 0.8491, F1: 0.7365\n",
      "Val   - Loss: 0.5242, Acc: 0.7650, AUC: 0.8419, F1: 0.7539\n",
      "Epoch 12/50\n",
      "Train - Loss: 0.4845, Acc: 0.7562, AUC: 0.8456, F1: 0.6890\n",
      "Val   - Loss: 0.5843, Acc: 0.7400, AUC: 0.8348, F1: 0.5873\n",
      "Epoch 13/50\n",
      "Train - Loss: 0.4648, Acc: 0.7950, AUC: 0.8626, F1: 0.7355\n",
      "Val   - Loss: 0.5417, Acc: 0.7550, AUC: 0.8617, F1: 0.7562\n",
      "Final model saved to ./models/rsna/model_attention.pth\n",
      "Epoch 14/50\n",
      "Train - Loss: 0.4828, Acc: 0.7950, AUC: 0.8567, F1: 0.7453\n",
      "Val   - Loss: 0.7004, Acc: 0.6800, AUC: 0.8430, F1: 0.6981\n",
      "Epoch 15/50\n",
      "Train - Loss: 0.4650, Acc: 0.7863, AUC: 0.8680, F1: 0.7316\n",
      "Val   - Loss: 0.5611, Acc: 0.7550, AUC: 0.8397, F1: 0.6316\n",
      "Epoch 16/50\n",
      "Train - Loss: 0.4638, Acc: 0.7925, AUC: 0.8635, F1: 0.7398\n",
      "Val   - Loss: 0.5552, Acc: 0.7600, AUC: 0.8355, F1: 0.7391\n",
      "Epoch 17/50\n",
      "Train - Loss: 0.4529, Acc: 0.7987, AUC: 0.8757, F1: 0.7564\n",
      "Val   - Loss: 0.7095, Acc: 0.7050, AUC: 0.8269, F1: 0.7094\n",
      "Epoch 18/50\n",
      "Train - Loss: 0.4831, Acc: 0.7825, AUC: 0.8612, F1: 0.7273\n",
      "Val   - Loss: 0.5367, Acc: 0.7600, AUC: 0.8403, F1: 0.6471\n",
      "Early stopping triggered.\n",
      "Model loaded successfully from ./models/rsna/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:64: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + [\"Negative\", \"Positive\"])\n",
      "/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:65: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + [\"Negative\", \"Positive\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved at output/attention/confusion_matrix.png\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Optimal Threshold: 0.3089\n",
      "Accuracy: 0.8000, AUC: 0.8485\n",
      "Precision: 0.8182, Recall: 0.7500, F1-Score: 0.7826\n",
      "Confusion Matrix:\n",
      "[[66 12]\n",
      " [18 54]]\n",
      "Attention heatmap 0 saved at output/attention/attention_heatmap_0.png\n",
      "Attention heatmap 1 saved at output/attention/attention_heatmap_1.png\n",
      "Attention heatmap 2 saved at output/attention/attention_heatmap_2.png\n",
      "Attention heatmap 3 saved at output/attention/attention_heatmap_3.png\n",
      "Attention heatmap 4 saved at output/attention/attention_heatmap_4.png\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▄▆▆▆▆▆▇▇█▆█████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▇▆▆▇▇▇█▇████</td></tr><tr><td>train_f1</td><td>▁▄▄▆▆▆▆▆▇▇█▆▇█▇██▇</td></tr><tr><td>train_loss</td><td>█▅▅▄▃▃▃▄▃▂▂▂▁▂▁▁▁▂</td></tr><tr><td>val_accuracy</td><td>▆▁▇▄▃▅█▇███▇▇▆▇█▆█</td></tr><tr><td>val_auc</td><td>▁▃▄▄▃▅▇▄▇▇▇▆█▇▇▆▆▇</td></tr><tr><td>val_f1</td><td>▅▆▇▁▇▇▇▆▇▇█▆█▇▆█▇▇</td></tr><tr><td>val_loss</td><td>▃▆▂█▇▄▁▂▁▁▂▃▂▅▂▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>18</td></tr><tr><td>pooling_type</td><td>attention</td></tr><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>test_auc</td><td>0.84847</td></tr><tr><td>test_f1</td><td>0.78261</td></tr><tr><td>test_precision</td><td>0.81818</td></tr><tr><td>test_recall</td><td>0.75</td></tr><tr><td>train_accuracy</td><td>0.7825</td></tr><tr><td>train_auc</td><td>0.86118</td></tr><tr><td>train_f1</td><td>0.72727</td></tr><tr><td>train_loss</td><td>0.48306</td></tr><tr><td>val_accuracy</td><td>0.76</td></tr><tr><td>val_auc</td><td>0.84033</td></tr><tr><td>val_f1</td><td>0.64706</td></tr><tr><td>val_loss</td><td>0.5367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-bird-156</strong> at: <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/ijcv4ma3' target=\"_blank\">https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/ijcv4ma3</a><br> View project at: <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG' target=\"_blank\">https://wandb.ai/javitrucas-universidad-de-granada/TFG</a><br>Synced 5 W&B file(s), 19 media file(s), 38 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250418_111257-ijcv4ma3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir config_1 en un objeto usando Box\n",
    "config_1 = Box({\n",
    "    \"dataset_name\": \"rsna-features_resnet18\",\n",
    "    \"input_feature_dim\": 512,  # Características de ResNet50\n",
    "    \"feature_dim\": 128,        # Dimensión final después de reducción\n",
    "    \"pooling_type\": \"attention\",\n",
    "    \"num_epochs\": 50,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 1,\n",
    "    \"val_prop\": 0.2,\n",
    "    \"seed\": 42,\n",
    "    \"use_inst_distances\": False,\n",
    "    \"adj_mat_mode\": \"relative\"\n",
    "})\n",
    "\n",
    "# Ejecutar el experimentoTFG\n",
    "run_experiment(config_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjavitrucas\u001b[0m (\u001b[33mjavitrucas-universidad-de-granada\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/javitrucas/TFG/notebooks/wandb/run-20250418_112820-mq6btmnv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/mq6btmnv' target=\"_blank\">whole-firefly-158</a></strong> to <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG' target=\"_blank\">https://wandb.ai/javitrucas-universidad-de-granada/TFG</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/mq6btmnv' target=\"_blank\">https://wandb.ai/javitrucas-universidad-de-granada/TFG/runs/mq6btmnv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panda\n",
      "[WSIDataset] Scanning files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WSIDataset] Building data dict:   2%|▏         | 207/8822 [01:07<52:03,  2.76it/s]  "
     ]
    }
   ],
   "source": [
    "config_panda = Box({\n",
    "    \"dataset_name\": \"panda-patches_512_preset-features_UNI\",\n",
    "    \"input_feature_dim\": 1024,  # Dimensionalidad de las características pre-extraídas\n",
    "    \"feature_dim\": 128,         # Dimensionalidad final después de reducción\n",
    "    \"pooling_type\": \"attention\",  # Tipo de pooling (puede ser 'attention', 'mean', 'max')\n",
    "    \"num_epochs\": 15,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 1,\n",
    "    \"val_prop\": 0.2,\n",
    "    \"seed\": 42,\n",
    "    \"use_inst_distances\": False,\n",
    "    \"adj_mat_mode\": \"relative\"\n",
    "})\n",
    "\n",
    "# Ejecutar el experimento\n",
    "run_experiment(config_panda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
