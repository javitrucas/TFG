{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio raíz del proyecto a sys.path\n",
    "project_root = \"/home/javitrucas/TFG\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # Para visualización de gráficas\n",
    "from torchvision.utils import make_grid  # Para visualizar imágenes\n",
    "import wandb  # Para registro con Weights & Biases\n",
    "from scripts.MNIST.MNISTMILDataset import MNISTMILDataset\n",
    "from scripts.MNIST.evaluation import ModelEvaluator\n",
    "from scripts.MNIST.training import Training\n",
    "\n",
    "# Configuración inicial\n",
    "output_model_dir = './models'  # Ruta relativa al directorio actual\n",
    "\n",
    "# Crear directorios si no existen\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "\n",
    "# Definir función para ejecutar experimentos\n",
    "def run_experiment(target_digit, bag_size, num_epochs, learning_rate, pooling_type):\n",
    "    \"\"\"\n",
    "    Ejecuta un experimento con los hiperparámetros dados y registra resultados en wandb.\n",
    "    \n",
    "    Args:\n",
    "        target_digit (int): Dígito objetivo para las bolsas.\n",
    "        bag_size (int): Número de instancias por bolsa.\n",
    "        num_epochs (int): Número de épocas de entrenamiento.\n",
    "        learning_rate (float): Tasa de aprendizaje.\n",
    "        pooling_type (str): Tipo de agrupación ('attention', 'mean', 'max').\n",
    "    \"\"\"\n",
    "    # Inicializar wandb\n",
    "    wandb.init(\n",
    "        project=\"TFG\",  # Nombre del proyecto en wandb\n",
    "        config={\n",
    "            \"target_digit\": target_digit,\n",
    "            \"bag_size\": bag_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"pooling_type\": pooling_type\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"=== Iniciando experimento ===\")\n",
    "    print(f\"Target Digit: {target_digit}, Bag Size: {bag_size}, Epochs: {num_epochs}, LR: {learning_rate}, Pooling: {pooling_type}\")\n",
    "    wandb.log({\"status\": \"Experiment started\", \"target_digit\": target_digit, \"bag_size\": bag_size, \"num_epochs\": num_epochs, \"learning_rate\": learning_rate, \"pooling_type\": pooling_type})\n",
    "    \n",
    "    # Crear datasets\n",
    "    print(\"Creando datasets...\")\n",
    "    train_dataset = MNISTMILDataset(subset=\"train\", bag_size=bag_size, obj_label=target_digit)\n",
    "    test_dataset = MNISTMILDataset(subset=\"test\", bag_size=bag_size, obj_label=target_digit)\n",
    "    wandb.log({\"status\": \"Datasets created\", \"train_dataset_size\": len(train_dataset), \"test_dataset_size\": len(test_dataset)})\n",
    "    \n",
    "    # Dividir el conjunto de entrenamiento en entrenamiento (80%) y validación (20%)\n",
    "    print(\"Dividiendo el conjunto de entrenamiento en entrenamiento (80%) y validación (20%)...\")\n",
    "    train_split_idx = int(len(train_dataset) * 0.8)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_split_idx, len(train_dataset) - train_split_idx])\n",
    "    wandb.log({\"status\": \"Training and validation split completed\", \"train_split_size\": len(train_dataset), \"val_split_size\": len(val_dataset)})\n",
    "    \n",
    "    # Entrenamiento\n",
    "    print(\"Iniciando entrenamiento...\")\n",
    "    trainer = Training(\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        output_model_dir=output_model_dir,\n",
    "        pooling_type=pooling_type\n",
    "    )\n",
    "    trainer.train()\n",
    "    wandb.log({\"status\": \"Training completed\"})\n",
    "    \n",
    "    # Registrar métricas de entrenamiento en wandb\n",
    "    if hasattr(trainer, 'train_losses') and hasattr(trainer, 'val_losses'):\n",
    "        print(\"Registrando métricas de entrenamiento en wandb...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": trainer.train_losses[epoch],\n",
    "                \"val_loss\": trainer.val_losses[epoch]\n",
    "            })\n",
    "        wandb.log({\"status\": \"Training metrics logged to wandb\"})\n",
    "    \n",
    "    # Evaluación\n",
    "    print(\"Evaluando el modelo...\")\n",
    "    evaluator = ModelEvaluator(\n",
    "        model_path=os.path.join(output_model_dir, 'model.pth'),\n",
    "        test_dataset=test_dataset,\n",
    "        batch_size=1,\n",
    "        pooling_type=pooling_type\n",
    "    )\n",
    "    \n",
    "    results, attention_weights = evaluator.evaluate()\n",
    "    wandb.log({\"status\": \"Model evaluation completed\", **results})\n",
    "    \n",
    "    # Mostrar gráficas de entrenamiento\n",
    "    if hasattr(trainer, 'train_losses') and hasattr(trainer, 'val_losses'):\n",
    "        print(\"Generando gráfica de pérdidas durante el entrenamiento...\")\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(trainer.train_losses, label='Train Loss')\n",
    "        plt.plot(trainer.val_losses, label='Validation Loss')\n",
    "        plt.title('Loss durante el entrenamiento')\n",
    "        plt.xlabel('Época')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        wandb.log({\"status\": \"Training loss plot generated\"})\n",
    "    \n",
    "    # Visualizar heatmaps de atención (si están disponibles)\n",
    "    if attention_weights is not None:\n",
    "        print(\"Mostrando heatmaps de atención mejorados...\")\n",
    "        \n",
    "        num_bags = min(5, len(attention_weights))  # Mostrar máximo 5 bolsas\n",
    "        \n",
    "        # Obtener rangos para normalización si es necesario\n",
    "        att_min, att_max = np.min(attention_weights), np.max(attention_weights)\n",
    "\n",
    "        for i, weights in enumerate(attention_weights[:num_bags]):\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(weights, cmap='inferno', aspect='auto', vmin=att_min, vmax=att_max)\n",
    "            plt.colorbar(label=\"Intensidad de atención\")\n",
    "            plt.title(f\"Heatmap de atención para la bolsa {i+1}\")\n",
    "            plt.xlabel(\"Elementos en la bolsa\")\n",
    "            plt.ylabel(\"Características\")\n",
    "            plt.show()\n",
    "            wandb.log({\"status\": f\"Attention heatmap for bag {i+1} generated\"})\n",
    "        \n",
    "        # Gráfica de la evolución de la atención\n",
    "        print(\"Generando gráfica de evolución de la atención...\")\n",
    "        mean_attention = [np.mean(weights) for weights in attention_weights]\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(mean_attention, marker='o', linestyle='-', color='blue', alpha=0.7)\n",
    "        plt.title(\"Evolución de la Intensidad de Atención por Bolsa\")\n",
    "        plt.xlabel(\"Bolsa\")\n",
    "        plt.ylabel(\"Media de Atención\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        wandb.log({\"status\": \"Attention evolution plot generated\"})\n",
    "\n",
    "        # Histograma de distribución de pesos de atención\n",
    "        print(\"Generando histograma de distribución de pesos de atención...\")\n",
    "        all_weights = np.concatenate([weights.flatten() for weights in attention_weights])\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.hist(all_weights, bins=30, color='purple', alpha=0.75)\n",
    "        plt.title(\"Distribución de Pesos de Atención\")\n",
    "        plt.xlabel(\"Valor de Atención\")\n",
    "        plt.ylabel(\"Frecuencia\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        wandb.log({\"status\": \"Attention distribution histogram generated\"})\n",
    "    \n",
    "    # Guardar el modelo como artefacto en wandb\n",
    "    print(\"Guardando el modelo como artefacto en wandb...\")\n",
    "    artifact = wandb.Artifact('trained_model', type='model')\n",
    "    artifact.add_file(os.path.join(output_model_dir, 'model.pth'))\n",
    "    wandb.log_artifact(artifact)\n",
    "    wandb.log({\"status\": \"Model saved as artifact in wandb\"})\n",
    "    \n",
    "    print(f\"=== Resultados del experimento ===\")\n",
    "    print(results)\n",
    "    print(f\"=== Fin del experimento ===\\n\")\n",
    "    \n",
    "    # Finalizar wandb\n",
    "    wandb.log({\"status\": \"Experiment finished\"})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento con pooling_type=\"attention\"\n",
    "params_attention = {\n",
    "    \"target_digit\": 3,\n",
    "    \"bag_size\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"pooling_type\": \"attention\"\n",
    "}\n",
    "run_experiment(**params_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento con pooling_type=\"mean\"\n",
    "params_mean = {\n",
    "    \"target_digit\": 3,\n",
    "    \"bag_size\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"pooling_type\": \"mean\"\n",
    "}\n",
    "run_experiment(**params_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento con pooling_type=\"max\"\n",
    "params_max = {\n",
    "    \"target_digit\": 3,\n",
    "    \"bag_size\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"pooling_type\": \"max\"\n",
    "}\n",
    "run_experiment(**params_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/javitrucas/miniconda3/envs/tfg/lib/python311.zip', '/home/javitrucas/miniconda3/envs/tfg/lib/python3.11', '/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/lib-dynload', '', '/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages', '/home/javitrucas/TFG', '/home/javitrucas/TFG/scripts', '/home/javitrucas/TFG/scripts']\n",
      "Últimos experimentos ejecutados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bag_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>pooling</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>max</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.987021</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.988302</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>max</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.988942</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>max</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.988302</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>max</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.987021</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bag_size  learning_rate pooling  seed  train_accuracy  train_auc  \\\n",
       "131        30           0.01     max     0        0.974375        0.5   \n",
       "132        30           0.01     max     1        0.976875        0.5   \n",
       "133        30           0.01     max     2        0.978125        0.5   \n",
       "134        30           0.01     max     3        0.976875        0.5   \n",
       "135        30           0.01     max     4        0.974375        0.5   \n",
       "\n",
       "     train_f1  test_accuracy  test_auc   test_f1  \n",
       "131  0.987021       0.972973       0.5  0.986301  \n",
       "132  0.988302       0.972973       0.5  0.986301  \n",
       "133  0.988942       0.972973       0.5  0.986301  \n",
       "134  0.988302       0.972973       0.5  0.986301  \n",
       "135  0.987021       0.972973       0.5  0.986301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejecución completada. Los resultados están en: mnist_experiment_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from scripts.MNIST.MNISTMILDataset import MNISTMILDataset\n",
    "from scripts.MNIST.training import Training\n",
    "from scripts.MNIST.evaluation import ModelEvaluator\n",
    "\n",
    "# Parámetros fijos y rejilla de búsqueda\n",
    "target_digit   = 3\n",
    "bag_sizes      = [10, 15, 30]\n",
    "learning_rates = [1e-4, 1e-3, 1e-2]\n",
    "pooling_types  = ['attention', 'mean', 'max']\n",
    "seeds          = list(range(5))    # cinco ejecuciones distintas\n",
    "\n",
    "# CSV de salida\n",
    "csv_file = 'mnist_experiment_runs.csv'\n",
    "\n",
    "# Definimos la cabecera (incluimos 'seed')\n",
    "fieldnames = [\n",
    "    'bag_size', 'learning_rate', 'pooling', 'seed',\n",
    "    'train_accuracy', 'train_auc', 'train_f1',\n",
    "    'test_accuracy',  'test_auc',  'test_f1'\n",
    "]\n",
    "\n",
    "# Cargamos el CSV existente o creamos uno nuevo\n",
    "if os.path.exists(csv_file):\n",
    "    df_done = pd.read_csv(csv_file)\n",
    "    print(\"Últimos experimentos ejecutados:\")\n",
    "    display(df_done.tail())\n",
    "    # Tupla de identificador único para cada ejecución\n",
    "    done_set = set(\n",
    "        zip(df_done.bag_size, df_done.learning_rate, df_done.pooling, df_done.seed)\n",
    "    )\n",
    "else:\n",
    "    df_done = pd.DataFrame(columns=fieldnames)\n",
    "    print(\"No se encontró CSV previo, empezando desde cero.\")\n",
    "    done_set = set()\n",
    "    # Creamos el CSV con cabecera\n",
    "    df_done.to_csv(csv_file, index=False)\n",
    "\n",
    "# Función para anotar un resultado al CSV\n",
    "def append_result(row: dict):\n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Iteramos solo las combinaciones pendientes\n",
    "for bag_size in bag_sizes:\n",
    "    full_train = MNISTMILDataset(subset=\"train\", bag_size=bag_size, obj_label=target_digit)\n",
    "    test_ds    = MNISTMILDataset(subset=\"test\",  bag_size=bag_size, obj_label=target_digit)\n",
    "    split_count = len(full_train)\n",
    "    split_idx   = int(split_count * 0.8)\n",
    "\n",
    "    for lr in learning_rates:\n",
    "        for pool in pooling_types:\n",
    "            for seed in seeds:\n",
    "                key = (bag_size, lr, pool, seed)\n",
    "                if key in done_set:\n",
    "                    # Ya hecho, saltamos\n",
    "                    continue\n",
    "\n",
    "                print(f\"\\n=== Ejecutando: bag_size={bag_size}, lr={lr}, pooling={pool}, seed={seed} ===\")\n",
    "\n",
    "                # Fijar semilla\n",
    "                random.seed(seed)\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "                # Split reproducible\n",
    "                g = torch.Generator().manual_seed(seed)\n",
    "                train_ds, val_ds = torch.utils.data.random_split(\n",
    "                    full_train,\n",
    "                    [split_idx, split_count - split_idx],\n",
    "                    generator=g\n",
    "                )\n",
    "\n",
    "                # Entrenamiento\n",
    "                trainer = Training(\n",
    "                    train_dataset=train_ds,\n",
    "                    val_dataset=val_ds,\n",
    "                    num_epochs=7,           # ajústalo si hace falta\n",
    "                    learning_rate=lr,\n",
    "                    output_model_dir='./models',\n",
    "                    pooling_type=pool\n",
    "                )\n",
    "                trainer.train()\n",
    "\n",
    "                # Eval en train\n",
    "                evaluator_train = ModelEvaluator(\n",
    "                    model_path=os.path.join('./models', 'model.pth'),\n",
    "                    test_dataset=train_ds,\n",
    "                    batch_size=1,\n",
    "                    pooling_type=pool\n",
    "                )\n",
    "                results_train, _ = evaluator_train.evaluate()\n",
    "\n",
    "                # Eval en test\n",
    "                evaluator_test = ModelEvaluator(\n",
    "                    model_path=os.path.join('./models', 'model.pth'),\n",
    "                    test_dataset=test_ds,\n",
    "                    batch_size=1,\n",
    "                    pooling_type=pool\n",
    "                )\n",
    "                results_test, _ = evaluator_test.evaluate()\n",
    "\n",
    "                # Preparamos fila\n",
    "                row = {\n",
    "                    'bag_size': bag_size,\n",
    "                    'learning_rate': lr,\n",
    "                    'pooling': pool,\n",
    "                    'seed': seed,\n",
    "                    'train_accuracy': results_train.get('accuracy'),\n",
    "                    'train_auc':      results_train.get('auc'),\n",
    "                    'train_f1':       results_train.get('f1_score'),\n",
    "                    'test_accuracy':  results_test.get('accuracy'),\n",
    "                    'test_auc':       results_test.get('auc'),\n",
    "                    'test_f1':        results_test.get('f1_score'),\n",
    "                }\n",
    "\n",
    "                # Guardamos y actualizamos el set\n",
    "                append_result(row)\n",
    "                done_set.add(key)\n",
    "\n",
    "print(\"\\nEjecución completada. Los resultados están en:\", csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
