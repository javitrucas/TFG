{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4197b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio raíz del proyecto a sys.path\n",
    "project_root = \"/home/javitrucas/TFG\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from box import Box\n",
    "from types import SimpleNamespace\n",
    "from scripts.dataset_loader import load_dataset\n",
    "from scripts.MIL_utils import MIL_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d335a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración general\n",
    "SAVE = True\n",
    "SAVE_PATH = './resultados/panda_heatmaps/'\n",
    "FIGSIZE = (10, 10)\n",
    "SAVE_EXTENSION = 'png'\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Configuración del dataset\n",
    "SIZE = 512\n",
    "RESIZE_SIZE = 256\n",
    "DATA_DIR = f'/data/data_fran/Panda/patches_{SIZE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148c3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panda\n",
      "[WSIDataset] Scanning files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WSIDataset] Building data dict: 100%|██████████| 1794/1794 [00:26<00:00, 68.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WSIDataset] Skipped 0 bags\n",
      "[WSIDataset] Found 1794 already processed bags\n"
     ]
    }
   ],
   "source": [
    "# Configuración para cargar el dataset\n",
    "config = Box({\n",
    "    \"dataset_name\": \"panda-patches_512_preset-features_UNI\",\n",
    "    \"input_feature_dim\": 1024,\n",
    "    \"feature_dim\": 128,\n",
    "    \"pooling_type\": \"attention\",\n",
    "    \"batch_size\": 1,\n",
    "    \"val_prop\": 0.2,\n",
    "    \"seed\": 42,\n",
    "    \"use_inst_distances\": False,\n",
    "    \"adj_mat_mode\": \"relative\"\n",
    "})\n",
    "\n",
    "# Cargar dataset de test\n",
    "test_dataset = load_dataset(config=config, mode=\"test\")\n",
    "\n",
    "# Función para normalizar valores\n",
    "def normalize(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "# Obtener longitudes de bolsas\n",
    "bag_len_list = []\n",
    "for idx in range(len(test_dataset)):\n",
    "    X, T, y, edge_index = test_dataset[idx]\n",
    "    bag_len_list.append(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65baa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos positivos encontrados: 587\n",
      "Caso seleccionado: 1551\n",
      "Número de parches: 52\n",
      "Etiquetas: 8 positivos, 44 negativos\n"
     ]
    }
   ],
   "source": [
    "# Ordenar índices por tamaño de bolsa\n",
    "idx_bag_names_sorted = np.argsort(bag_len_list)\n",
    "\n",
    "# Extraer índices de bolsas positivas\n",
    "idx_pos_bags_sorted = []\n",
    "for idx in idx_bag_names_sorted:\n",
    "    X, T, y, edge_index = test_dataset[idx]\n",
    "    \n",
    "    # Asumiendo que consideramos un caso positivo si al menos un parche está etiquetado como 1\n",
    "    if 1 in y:\n",
    "        idx_pos_bags_sorted.append(idx)\n",
    "    \n",
    "print(f\"Casos positivos encontrados: {len(idx_pos_bags_sorted)}\")\n",
    "\n",
    "# Seleccionar un caso positivo\n",
    "if len(idx_pos_bags_sorted) > 0:\n",
    "    BAG_IDX = idx_pos_bags_sorted[5] if len(idx_pos_bags_sorted) > 5 else idx_pos_bags_sorted[0]\n",
    "    X, T, y, edge_index = test_dataset[BAG_IDX]\n",
    "    adj_mat = edge_index.to_dense()\n",
    "\n",
    "    print(f\"Caso seleccionado: {BAG_IDX}\")\n",
    "    print(f\"Número de parches: {len(X)}\")\n",
    "    \n",
    "    # Mostrar información sobre las etiquetas\n",
    "    num_positive = (y == 1).sum().item()\n",
    "    num_negative = (y == 0).sum().item()\n",
    "    print(f\"Etiquetas: {num_positive} positivos, {num_negative} negativos\")\n",
    "    \n",
    "    # Si quieres mostrar las etiquetas completas (podría ser muy largo)\n",
    "    # print(f\"Etiquetas de parches: {y}\")\n",
    "else:\n",
    "    print(\"No se encontraron casos positivos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6322dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles en el CSV:\n",
      "['image_id', 'data_provider', 'isup_grade', 'gleason_score', 'Partition']\n",
      "Analizando WSI con ID: 0005f7aaab2800f6170c399693a96917\n",
      "Se encontraron 1 parches para este WSI\n",
      "No se encontró una columna para patch_id\n",
      "No se encontraron columnas 'row' y 'col' para la visualización de coordenadas\n",
      "\n",
      "Resumen de datos disponibles:\n",
      "       isup_grade  label\n",
      "count         1.0    1.0\n",
      "mean          0.0    0.0\n",
      "std           NaN    NaN\n",
      "min           0.0    0.0\n",
      "25%           0.0    0.0\n",
      "50%           0.0    0.0\n",
      "75%           0.0    0.0\n",
      "max           0.0    0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2922663/4000169243.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wsi_metadata[new_col] = wsi_metadata[old_col]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Parámetros del dataset\n",
    "SIZE = 512\n",
    "DATA_DIR = f'/data/data_fran/Panda/patches_{SIZE}'\n",
    "csv_path = '/data/datasets/PANDA/PANDA_original/original/wsi_labels.csv'\n",
    "\n",
    "# Leer el CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Mostrar las columnas disponibles para verificar\n",
    "print(\"Columnas disponibles en el CSV:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Seleccionar un índice específico de bolsa / slide\n",
    "# Veamos un ejemplo con el primer image_id disponible\n",
    "BAG_IDX = df['image_id'].iloc[0]  # Puedes cambiarlo por el ID deseado\n",
    "print(f\"Analizando WSI con ID: {BAG_IDX}\")\n",
    "\n",
    "# Filtrar los parches pertenecientes a esa WSI\n",
    "wsi_metadata = df[df['image_id'] == BAG_IDX]\n",
    "\n",
    "# Verificar si hay datos\n",
    "if wsi_metadata.empty:\n",
    "    print(f\"No se encontraron datos para el WSI con ID: {BAG_IDX}\")\n",
    "else:\n",
    "    print(f\"Se encontraron {len(wsi_metadata)} parches para este WSI\")\n",
    "\n",
    "    # Comprobar si las columnas esperadas existen\n",
    "    expected_cols = ['patch_id', 'row', 'col', 'isup_grade']\n",
    "    available_cols = wsi_metadata.columns.tolist()\n",
    "    \n",
    "    # Mapear columnas si tienen nombres diferentes\n",
    "    col_mapping = {}\n",
    "    \n",
    "    if 'patch_id' not in available_cols:\n",
    "        # Intentar encontrar una columna alternativa para los parches\n",
    "        if 'patch_name' in available_cols:\n",
    "            col_mapping['patch_id'] = 'patch_name'\n",
    "        else:\n",
    "            print(\"No se encontró una columna para patch_id\")\n",
    "    \n",
    "    if 'isup_grade' in available_cols:\n",
    "        # Para el PANDA dataset, la etiqueta es el grado ISUP\n",
    "        col_mapping['label'] = 'isup_grade'\n",
    "    elif 'data_provider' in available_cols:\n",
    "        # Si no hay isup_grade, podemos usar otra columna para demostración\n",
    "        col_mapping['label'] = 'data_provider'\n",
    "    \n",
    "    # Aplicar mapeo de columnas\n",
    "    for new_col, old_col in col_mapping.items():\n",
    "        if old_col in available_cols:\n",
    "            wsi_metadata[new_col] = wsi_metadata[old_col]\n",
    "    \n",
    "    # Extraer las coordenadas si están disponibles\n",
    "    if 'row' in available_cols and 'col' in available_cols:\n",
    "        # Listas con info útil\n",
    "        if 'patch_id' in wsi_metadata.columns:\n",
    "            PATCH_NAMES = wsi_metadata['patch_id'].tolist()\n",
    "        else:\n",
    "            PATCH_NAMES = [f\"patch_{i}\" for i in range(len(wsi_metadata))]\n",
    "        \n",
    "        if 'label' in wsi_metadata.columns:\n",
    "            PATCH_LABELS = wsi_metadata['label'].tolist()\n",
    "        else:\n",
    "            PATCH_LABELS = [0] * len(wsi_metadata)\n",
    "        \n",
    "        row_list = wsi_metadata['row'].tolist()\n",
    "        column_list = wsi_metadata['col'].tolist()\n",
    "\n",
    "        # Normalizar coordenadas\n",
    "        ROW_ARRAY = np.array(row_list)\n",
    "        COL_ARRAY = np.array(column_list)\n",
    "        min_row, min_col = ROW_ARRAY.min(), COL_ARRAY.min()\n",
    "        ROW_ARRAY = ROW_ARRAY - min_row + 1\n",
    "        COL_ARRAY = COL_ARRAY - min_col + 1\n",
    "\n",
    "        # Tamaño del grid para la WSI\n",
    "        MAX_ROW = int(ROW_ARRAY.max())\n",
    "        MAX_COL = int(COL_ARRAY.max())\n",
    "        print(f\"Dimensiones normalizadas: {MAX_ROW} x {MAX_COL}\")\n",
    "\n",
    "        # Crear una matriz para visualizar los parches\n",
    "        grid = np.zeros((MAX_ROW, MAX_COL))\n",
    "        \n",
    "        # Llenar la matriz con los valores de etiqueta\n",
    "        for i in range(len(PATCH_LABELS)):\n",
    "            row_idx = int(ROW_ARRAY[i]) - 1  # Índices basados en 0\n",
    "            col_idx = int(COL_ARRAY[i]) - 1\n",
    "            \n",
    "            # Verificar que estamos dentro de los límites\n",
    "            if 0 <= row_idx < MAX_ROW and 0 <= col_idx < MAX_COL:\n",
    "                # Convertir etiquetas a valores numéricos si no lo son\n",
    "                if isinstance(PATCH_LABELS[i], (int, float)):\n",
    "                    grid[row_idx, col_idx] = PATCH_LABELS[i]\n",
    "                else:\n",
    "                    # Si es un string, asignar un valor numérico para visualización\n",
    "                    grid[row_idx, col_idx] = hash(PATCH_LABELS[i]) % 10\n",
    "        \n",
    "        # Visualizar la matriz\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(grid, cmap='viridis')\n",
    "        plt.colorbar(label='Etiqueta')\n",
    "        plt.title(f'Visualización de WSI: {BAG_IDX}')\n",
    "        plt.xlabel('Columna')\n",
    "        plt.ylabel('Fila')\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'wsi_visualization_{BAG_IDX}.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # Mostrar estadísticas de las etiquetas\n",
    "        unique_labels = set(PATCH_LABELS)\n",
    "        print(f\"Etiquetas únicas: {unique_labels}\")\n",
    "        for label in unique_labels:\n",
    "            count = PATCH_LABELS.count(label)\n",
    "            print(f\"  Etiqueta {label}: {count} parches ({count/len(PATCH_LABELS)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No se encontraron columnas 'row' y 'col' para la visualización de coordenadas\")\n",
    "        \n",
    "        # Mostrar un resumen de los datos disponibles\n",
    "        print(\"\\nResumen de datos disponibles:\")\n",
    "        print(wsi_metadata.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1010ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATCH_NAMES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cargar las imágenes de los parches\u001b[39;00m\n\u001b[32m      2\u001b[39m patches_list = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pbar = tqdm(total=\u001b[38;5;28mlen\u001b[39m(\u001b[43mPATCH_NAMES\u001b[49m))\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m patch_name \u001b[38;5;129;01min\u001b[39;00m PATCH_NAMES:\n\u001b[32m      5\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'PATCH_NAMES' is not defined"
     ]
    }
   ],
   "source": [
    "# Cargar las imágenes de los parches\n",
    "patches_list = []\n",
    "pbar = tqdm(total=len(PATCH_NAMES))\n",
    "for patch_name in PATCH_NAMES:\n",
    "    pbar.update(1)\n",
    "    # Ajusta la ruta según tu estructura\n",
    "    img = cv2.imread(f'{DATA_DIR}/images/{patch_name}.jpg')\n",
    "    if img is None:  # Intenta con extensión alternativa si falla\n",
    "        img = cv2.imread(f'{DATA_DIR}/images/{patch_name}.png')\n",
    "    \n",
    "    if img is not None:\n",
    "        if RESIZE_SIZE != SIZE:\n",
    "            img = cv2.resize(img, (RESIZE_SIZE, RESIZE_SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        patches_list.append(img)\n",
    "    else:\n",
    "        print(f\"No se pudo cargar la imagen: {patch_name}\")\n",
    "        # Crear una imagen en blanco como fallback\n",
    "        patches_list.append(np.ones((RESIZE_SIZE, RESIZE_SIZE, 3), dtype=np.uint8) * 255)\n",
    "\n",
    "# Crear canvas para la WSI completa\n",
    "MAX_X = (MAX_COL+2) * RESIZE_SIZE\n",
    "MAX_Y = (MAX_ROW+2) * RESIZE_SIZE\n",
    "canvas_wsi = np.ones((MAX_Y, MAX_X, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Colocar parches en el canvas\n",
    "for i, patch in enumerate(patches_list):\n",
    "    row = ROW_ARRAY[i]\n",
    "    column = COL_ARRAY[i]\n",
    "    x = column * RESIZE_SIZE\n",
    "    y = row * RESIZE_SIZE\n",
    "    canvas_wsi[y:y+RESIZE_SIZE, x:x+RESIZE_SIZE] = patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wsi_and_heatmap(ax, wsi, heatmap=None, size=RESIZE_SIZE, plot_patch_contour=True, \n",
    "                          row_array=None, col_array=None, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Visualiza una WSI con su heatmap superpuesto.\n",
    "    \n",
    "    Args:\n",
    "        ax: Matplotlib axis\n",
    "        wsi: Canvas con la imagen WSI\n",
    "        heatmap: Valores del heatmap (opcional)\n",
    "        size: Tamaño de cada parche\n",
    "        plot_patch_contour: Si se dibujan o no los contornos de los parches\n",
    "        row_array: Array con las coordenadas de fila de cada parche\n",
    "        col_array: Array con las coordenadas de columna de cada parche\n",
    "        alpha: Transparencia del heatmap\n",
    "    \"\"\"\n",
    "    ax.imshow(wsi)\n",
    "    \n",
    "    # Si se proporciona un heatmap, superponerlo\n",
    "    if heatmap is not None:\n",
    "        # Crear matriz para el heatmap\n",
    "        if isinstance(heatmap, list):\n",
    "            heatmap = np.array(heatmap)\n",
    "        \n",
    "        # Crear un mapa de calor vacío del tamaño del canvas\n",
    "        hm = np.zeros((wsi.shape[0], wsi.shape[1]))\n",
    "        \n",
    "        # Llenar el mapa de calor con los valores\n",
    "        for i in range(len(row_array)):\n",
    "            row = row_array[i]\n",
    "            col = col_array[i]\n",
    "            y = row * size\n",
    "            x = col * size\n",
    "            value = heatmap[i]\n",
    "            hm[y:y+size, x:x+size] = value\n",
    "        \n",
    "        # Crear una colormap personalizada\n",
    "        import matplotlib.cm as cm\n",
    "        from matplotlib.colors import ListedColormap\n",
    "        \n",
    "        N = 256\n",
    "        vals = np.ones((N, 4))\n",
    "        vals[:, 0] = np.linspace(0.17254901960784313, 0.8392156862745098, N)\n",
    "        vals[:, 1] = np.linspace(0.6274509803921569, 0.15294117647058825, N)\n",
    "        vals[:, 2] = np.linspace(0.17254901960784313, 0.1568627450980392, N)\n",
    "        cmap = ListedColormap(vals)\n",
    "        \n",
    "        # Mostrar el heatmap\n",
    "        ax.imshow(hm, alpha=alpha, cmap=cmap, vmin=0, vmax=1)\n",
    "    \n",
    "    # Dibujar contornos de los parches si se solicita\n",
    "    if plot_patch_contour:\n",
    "        for i in range(len(row_array)):\n",
    "            row = row_array[i]\n",
    "            col = col_array[i]\n",
    "            y = row * size\n",
    "            x = col * size\n",
    "            rect = plt.Rectangle((x, y), size, size, fill=False, edgecolor='black', linewidth=0.5)\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar WSI con y sin etiquetas\n",
    "fig, ax = plt.subplots(figsize=(10,10), nrows=2)\n",
    "ax[0] = plot_wsi_and_heatmap(ax[0], canvas_wsi, size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "ax[1] = plot_wsi_and_heatmap(ax[1], canvas_wsi, PATCH_LABELS, size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "ax[0].set_title(\"WSI Original\")\n",
    "ax[1].set_title(\"Etiquetas de parches\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Guardar figuras\n",
    "if SAVE:\n",
    "    # Guardar WSI sin etiquetas\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    ax = plot_wsi_and_heatmap(ax, canvas_wsi, size=RESIZE_SIZE, \n",
    "                             plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "    plt.savefig(f'{SAVE_PATH}/panda_wsi_patched.{SAVE_EXTENSION}', bbox_inches='tight')\n",
    "    \n",
    "    # Guardar WSI con etiquetas\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    ax = plot_wsi_and_heatmap(ax, canvas_wsi, PATCH_LABELS, size=RESIZE_SIZE, \n",
    "                             plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "    plt.savefig(f'{SAVE_PATH}/panda_wsi_patched_labels.{SAVE_EXTENSION}', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd180e34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATCH_LABELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Suavizar etiquetas basado en los vecinos\u001b[39;00m\n\u001b[32m      2\u001b[39m changes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m old_patch_labels = \u001b[43mPATCH_LABELS\u001b[49m.copy()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      6\u001b[39m     new_patch_labels = []\n",
      "\u001b[31mNameError\u001b[39m: name 'PATCH_LABELS' is not defined"
     ]
    }
   ],
   "source": [
    "# Suavizar etiquetas basado en los vecinos\n",
    "changes = False\n",
    "old_patch_labels = PATCH_LABELS.copy()\n",
    "\n",
    "while True:\n",
    "    new_patch_labels = []\n",
    "    changes = False\n",
    "    \n",
    "    for i in range(len(old_patch_labels)):\n",
    "        sum_pos = 0\n",
    "        sum_neg = 0\n",
    "        for j in range(len(old_patch_labels)):\n",
    "            if adj_mat[i, j] > 0:\n",
    "                if old_patch_labels[j] == 1:\n",
    "                    sum_pos += 1\n",
    "                else:\n",
    "                    sum_neg += 1\n",
    "         \n",
    "        if sum_pos > sum_neg:\n",
    "            new_label = 1\n",
    "        else:\n",
    "            new_label = 0\n",
    "        new_patch_labels.append(new_label)\n",
    "        if new_label != old_patch_labels[i]:\n",
    "            changes = True\n",
    "    \n",
    "    if not changes:\n",
    "        break\n",
    "    old_patch_labels = new_patch_labels.copy()\n",
    "\n",
    "print(\"Suavizado de etiquetas finalizado\")\n",
    "\n",
    "# Visualizar resultados del suavizado\n",
    "fig, ax = plt.subplots(figsize=(10,10), ncols=2)\n",
    "ax[0] = plot_wsi_and_heatmap(ax[0], canvas_wsi, PATCH_LABELS, size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "ax[1] = plot_wsi_and_heatmap(ax[1], canvas_wsi, new_patch_labels, size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "ax[0].set_title(\"Etiquetas originales\")\n",
    "ax[1].set_title(\"Etiquetas suavizadas\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Actualizar etiquetas\n",
    "PATCH_LABELS = new_patch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69763da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de rutas de modelos entrenados\n",
    "# (Aquí debes usar las rutas de tus modelos)\n",
    "run_ids = {\n",
    "    'attention': 'tu_run_id_attention',\n",
    "    'mean': 'tu_run_id_mean',\n",
    "    'max': 'tu_run_id_max'\n",
    "}\n",
    "\n",
    "# Configuración para cargar modelos\n",
    "from scripts.medical_scripts.medical_evaluation import ModelEvaluator\n",
    "from scripts.MIL_utils import MIL_collate_fn\n",
    "\n",
    "# Preparar datos para predicción\n",
    "X_batch = X.unsqueeze(0)  # Añadir dimensión de batch\n",
    "T_batch = T.unsqueeze(0) if T is not None else None\n",
    "y_batch = y.unsqueeze(0)\n",
    "edge_index_batch = edge_index.unsqueeze(0) if edge_index is not None else None\n",
    "mask = torch.ones_like(y_batch)\n",
    "\n",
    "# Diccionario para almacenar predicciones\n",
    "f_pred_dict = {}\n",
    "\n",
    "# Cargar y aplicar cada modelo\n",
    "for model_name, run_id in run_ids.items():\n",
    "    print(f\"Procesando modelo: {model_name}\")\n",
    "    \n",
    "    # Cargar configuración del modelo desde wandb\n",
    "    api = wandb.Api()\n",
    "    try:\n",
    "        run = api.run(f\"tu_usuario/TFG/{run_id}\")\n",
    "        config_dict = run.config\n",
    "        \n",
    "        # Crear configuración para evaluador\n",
    "        config = Box({\n",
    "            \"dataset_name\": config_dict[\"dataset_name\"],\n",
    "            \"input_feature_dim\": config_dict[\"input_feature_dim\"],\n",
    "            \"feature_dim\": config_dict[\"feature_dim\"],\n",
    "            \"pooling_type\": model_name,\n",
    "            \"batch_size\": 1\n",
    "        })\n",
    "        \n",
    "        # Ruta al modelo guardado\n",
    "        model_path = f\"./models/{config.dataset_name.split('-')[0]}/{model_name}/model.pth\"\n",
    "        \n",
    "        # Crear el evaluador\n",
    "        evaluator = ModelEvaluator(\n",
    "            model_path=model_path,\n",
    "            test_loader=None,\n",
    "            batch_size=1,\n",
    "            input_feature_dim=config.input_feature_dim,\n",
    "            feature_dim=config.feature_dim,\n",
    "            pooling_type=model_name,\n",
    "            wandb=None\n",
    "        )\n",
    "        \n",
    "        # Obtener el modelo y ponerlo en modo evaluación\n",
    "        model = evaluator.model\n",
    "        model.eval()\n",
    "        \n",
    "        # Predecir atenciones\n",
    "        with torch.no_grad():\n",
    "            # Esto dependerá de la estructura de tu modelo\n",
    "            # Ajusta estas líneas según tu implementación\n",
    "            if hasattr(model, 'predict_attentions'):\n",
    "                _, attn = model.predict_attentions(X_batch, edge_index_batch, mask)\n",
    "                f_pred = attn.squeeze(0).cpu().numpy()\n",
    "            else:\n",
    "                # Función alternativa para extraer atenciones\n",
    "                # Por ejemplo, con un forward hook para capturar el mapa de atención\n",
    "                attn_maps = []\n",
    "                \n",
    "                def hook_fn(module, input, output):\n",
    "                    attn_maps.append(output)\n",
    "                \n",
    "                # Registrar hook en la capa de atención\n",
    "                if hasattr(model, 'attention'):\n",
    "                    hook = model.attention.register_forward_hook(hook_fn)\n",
    "                    \n",
    "                _ = model(X_batch, edge_index_batch, mask)\n",
    "                \n",
    "                if attn_maps:\n",
    "                    f_pred = attn_maps[0].squeeze(0).cpu().numpy()\n",
    "                    hook.remove()\n",
    "                else:\n",
    "                    # Si no se puede extraer la atención, usa una distribución uniforme\n",
    "                    f_pred = np.ones(len(X)) / len(X)\n",
    "        \n",
    "        # Normalizar predicciones\n",
    "        f_pred = normalize(f_pred)\n",
    "        f_pred_dict[model_name] = f_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo {model_name}: {e}\")\n",
    "        f_pred_dict[model_name] = np.ones(len(X)) / len(X)  # Atención uniforme como fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e74717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar mapas de atención de todos los modelos\n",
    "fig, ax = plt.subplots(figsize=(15,10), ncols=len(f_pred_dict))\n",
    "if len(f_pred_dict) == 1:\n",
    "    ax = [ax]  # Convertir a lista si solo hay un modelo\n",
    "\n",
    "for i, (model_name, f_pred) in enumerate(f_pred_dict.items()):\n",
    "    ax[i] = plot_wsi_and_heatmap(ax[i], canvas_wsi, f_pred, size=RESIZE_SIZE, \n",
    "                                plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "    ax[i].set_title(model_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Guardar mapas de atención individuales\n",
    "if SAVE:\n",
    "    for model_name, f_pred in f_pred_dict.items():\n",
    "        fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "        ax = plot_wsi_and_heatmap(ax, canvas_wsi, f_pred, size=RESIZE_SIZE, \n",
    "                                 plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "        ax.set_title(model_name)\n",
    "        \n",
    "        # Añadir barra de color\n",
    "        from matplotlib.colors import ListedColormap\n",
    "        import matplotlib.cm as cm\n",
    "        from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "        \n",
    "        N = 256\n",
    "        vals = np.ones((N, 4))\n",
    "        vals[:, 0] = np.linspace(0.17254901960784313, 0.8392156862745098, N)\n",
    "        vals[:, 1] = np.linspace(0.6274509803921569, 0.15294117647058825, N)\n",
    "        vals[:, 2] = np.linspace(0.17254901960784313, 0.1568627450980392, N)\n",
    "        cmap = ListedColormap(vals)\n",
    "        \n",
    "        cbaxes = inset_axes(ax, width=\"30%\", height=\"3%\", loc='upper right') \n",
    "        fig.colorbar(\n",
    "            cm.ScalarMappable(norm=None, cmap=cmap), \n",
    "            cax=cbaxes, \n",
    "            orientation='horizontal',\n",
    "            ticks=[0,1]\n",
    "        )\n",
    "        \n",
    "        plt.savefig(f'{SAVE_PATH}/panda_wsi_attention_{model_name}.{SAVE_EXTENSION}', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e762749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparativa entre etiquetas de parches y mejor modelo de atención\n",
    "# Seleccionar el modelo con mejor rendimiento (puedes ajustar este criterio)\n",
    "best_model = list(f_pred_dict.keys())[0]  # Por defecto, usar el primero\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5), ncols=3)\n",
    "ax[0] = plot_wsi_and_heatmap(ax[0], canvas_wsi, size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "ax[1] = plot_wsi_and_heatmap(ax[1], canvas_wsi, PATCH_LABELS, size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "ax[2] = plot_wsi_and_heatmap(ax[2], canvas_wsi, f_pred_dict[best_model], size=RESIZE_SIZE, \n",
    "                            plot_patch_contour=True, row_array=ROW_ARRAY, col_array=COL_ARRAY)\n",
    "\n",
    "ax[0].set_title(\"WSI Original\")\n",
    "ax[1].set_title(\"Etiquetas de parches\")\n",
    "ax[2].set_title(f\"Atención ({best_model})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if SAVE:\n",
    "    plt.savefig(f'{SAVE_PATH}/panda_wsi_comparison.{SAVE_EXTENSION}', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e64bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis cuantitativo - correlación entre etiquetas y mapas de atención\n",
    "correlations = {}\n",
    "for model_name, f_pred in f_pred_dict.items():\n",
    "    # Correlación de Pearson\n",
    "    corr = np.corrcoef(np.array(PATCH_LABELS), f_pred)[0,1]\n",
    "    correlations[model_name] = corr\n",
    "    print(f\"Correlación con {model_name}: {corr:.4f}\")\n",
    "\n",
    "# Visualizar correlaciones\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(correlations.keys(), correlations.values())\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.ylabel(\"Correlación con etiquetas\")\n",
    "plt.title(\"Correlación entre mapas de atención y etiquetas de parches\")\n",
    "plt.ylim(0, 1)  # Ajusta según tus resultados\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if SAVE:\n",
    "    plt.savefig(f'{SAVE_PATH}/correlations.{SAVE_EXTENSION}', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
