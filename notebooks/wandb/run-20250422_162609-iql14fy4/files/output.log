panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|██████████| 8822/8822 [01:41<00:00, 87.21it/s]
[WSIDataset] Building data dict: 100%|██████████| 1794/1794 [00:18<00:00, 94.63it/s] 
[WSIDataset] Skipped 5 bags
[WSIDataset] Found 8817 already processed bags
panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|█████████▉| 1792/1794 [00:18<00:00, 92.27it/s]
[WSIDataset] Skipped 0 bags
[WSIDataset] Found 1794 already processed bags
Epoch 1/15
Train - Loss: 0.2164, Acc: 0.9196, AUC: 0.9676, F1: 0.9448
Val   - Loss: 0.1626, Acc: 0.9473, AUC: 0.9824, F1: 0.9630
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 2/15
Train - Loss: 0.1760, Acc: 0.9324, AUC: 0.9790, F1: 0.9535
Val   - Loss: 0.2656, Acc: 0.9059, AUC: 0.9834, F1: 0.9383
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 3/15
Train - Loss: 0.1687, Acc: 0.9405, AUC: 0.9819, F1: 0.9590
Val   - Loss: 0.1623, Acc: 0.9410, AUC: 0.9822, F1: 0.9595
Epoch 4/15
Train - Loss: 0.1704, Acc: 0.9370, AUC: 0.9823, F1: 0.9568
Val   - Loss: 0.1824, Acc: 0.9450, AUC: 0.9837, F1: 0.9618
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 5/15
Train - Loss: 0.1690, Acc: 0.9433, AUC: 0.9834, F1: 0.9610
Val   - Loss: 0.1784, Acc: 0.9495, AUC: 0.9838, F1: 0.9648
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 6/15
Train - Loss: 0.1675, Acc: 0.9467, AUC: 0.9847, F1: 0.9633
Val   - Loss: 0.3047, Acc: 0.9150, AUC: 0.9828, F1: 0.9385
Epoch 7/15
Train - Loss: 0.1849, Acc: 0.9409, AUC: 0.9832, F1: 0.9593
Val   - Loss: 0.2580, Acc: 0.9099, AUC: 0.9845, F1: 0.9409
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 8/15
Train - Loss: 0.1806, Acc: 0.9417, AUC: 0.9842, F1: 0.9600
Val   - Loss: 0.2889, Acc: 0.9382, AUC: 0.9808, F1: 0.9575
Epoch 9/15
Train - Loss: 0.1781, Acc: 0.9434, AUC: 0.9839, F1: 0.9611
Val   - Loss: 0.2363, Acc: 0.9422, AUC: 0.9844, F1: 0.9601
Epoch 10/15
Train - Loss: 0.1741, Acc: 0.9447, AUC: 0.9851, F1: 0.9620
Val   - Loss: 0.2284, Acc: 0.9286, AUC: 0.9749, F1: 0.9507
Epoch 11/15
Train - Loss: 0.1802, Acc: 0.9460, AUC: 0.9845, F1: 0.9628
Val   - Loss: 0.2223, Acc: 0.9388, AUC: 0.9853, F1: 0.9587
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 12/15
Train - Loss: 0.1684, Acc: 0.9467, AUC: 0.9856, F1: 0.9633
Val   - Loss: 0.2292, Acc: 0.9478, AUC: 0.9854, F1: 0.9643
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 13/15
Train - Loss: 0.1935, Acc: 0.9433, AUC: 0.9839, F1: 0.9610
Val   - Loss: 0.2021, Acc: 0.9393, AUC: 0.9844, F1: 0.9590
Epoch 14/15
Train - Loss: 0.1739, Acc: 0.9504, AUC: 0.9855, F1: 0.9659
Val   - Loss: 0.3509, Acc: 0.9031, AUC: 0.9776, F1: 0.9362
Epoch 15/15
Train - Loss: 0.2041, Acc: 0.9426, AUC: 0.9825, F1: 0.9605
Val   - Loss: 0.1968, Acc: 0.9484, AUC: 0.9856, F1: 0.9643
Final model saved to ./models/panda/attention/model_attention.pth
Model loaded successfully from ./models/panda/attention/model.pth
  ax.set_xticklabels([''] + ["Negative", "Positive"])
/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:65: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels([''] + ["Negative", "Positive"])
Confusion matrix saved at output/attention/confusion_matrix.png

--- Evaluation Results ---
Optimal Threshold: 0.7537
Accuracy: 0.9509, AUC: 0.9861
Precision: 0.9817, Recall: 0.9499, F1-Score: 0.9655
Confusion Matrix:
[[ 474   23]
 [  65 1232]]
Attention heatmap 0 saved at output/attention/attention_heatmap_0.png
Attention heatmap 1 saved at output/attention/attention_heatmap_1.png
Attention heatmap 2 saved at output/attention/attention_heatmap_2.png
Attention heatmap 3 saved at output/attention/attention_heatmap_3.png
Attention heatmap 4 saved at output/attention/attention_heatmap_4.png
