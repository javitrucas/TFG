panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|██████████| 8822/8822 [01:43<00:00, 84.97it/s]
[WSIDataset] Building data dict: 100%|██████████| 1794/1794 [00:18<00:00, 97.12it/s] 
[WSIDataset] Skipped 5 bags
[WSIDataset] Found 8817 already processed bags
panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|█████████▉| 1791/1794 [00:18<00:00, 97.43it/s] 
[WSIDataset] Skipped 0 bags
[WSIDataset] Found 1794 already processed bags
Epoch 1/15
Train - Loss: 0.1694, Acc: 0.9345, AUC: 0.9772, F1: 0.9550
Val   - Loss: 0.1327, Acc: 0.9473, AUC: 0.9859, F1: 0.9633
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 2/15
Train - Loss: 0.1343, Acc: 0.9453, AUC: 0.9850, F1: 0.9622
Val   - Loss: 0.1269, Acc: 0.9541, AUC: 0.9896, F1: 0.9679
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 3/15
Train - Loss: 0.1223, Acc: 0.9494, AUC: 0.9880, F1: 0.9651
Val   - Loss: 0.1140, Acc: 0.9580, AUC: 0.9898, F1: 0.9709
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 4/15
Train - Loss: 0.1109, Acc: 0.9556, AUC: 0.9896, F1: 0.9694
Val   - Loss: 0.1387, Acc: 0.9359, AUC: 0.9910, F1: 0.9572
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 5/15
Train - Loss: 0.1058, Acc: 0.9582, AUC: 0.9907, F1: 0.9711
Val   - Loss: 0.1182, Acc: 0.9546, AUC: 0.9910, F1: 0.9684
Epoch 6/15
Train - Loss: 0.1024, Acc: 0.9602, AUC: 0.9910, F1: 0.9725
Val   - Loss: 0.1035, Acc: 0.9580, AUC: 0.9919, F1: 0.9708
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 7/15
Train - Loss: 0.0968, Acc: 0.9614, AUC: 0.9920, F1: 0.9734
Val   - Loss: 0.1167, Acc: 0.9552, AUC: 0.9910, F1: 0.9688
Epoch 8/15
Train - Loss: 0.0925, Acc: 0.9651, AUC: 0.9926, F1: 0.9760
Val   - Loss: 0.0974, Acc: 0.9615, AUC: 0.9925, F1: 0.9734
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 9/15
Train - Loss: 0.0894, Acc: 0.9657, AUC: 0.9931, F1: 0.9763
Val   - Loss: 0.1033, Acc: 0.9609, AUC: 0.9915, F1: 0.9730
Epoch 10/15
Train - Loss: 0.0888, Acc: 0.9663, AUC: 0.9930, F1: 0.9767
Val   - Loss: 0.1057, Acc: 0.9592, AUC: 0.9914, F1: 0.9719
Epoch 11/15
Train - Loss: 0.0809, Acc: 0.9685, AUC: 0.9943, F1: 0.9783
Val   - Loss: 0.1074, Acc: 0.9592, AUC: 0.9922, F1: 0.9714
Epoch 12/15
Train - Loss: 0.0803, Acc: 0.9692, AUC: 0.9943, F1: 0.9788
Val   - Loss: 0.1112, Acc: 0.9586, AUC: 0.9908, F1: 0.9714
Epoch 13/15
Train - Loss: 0.0787, Acc: 0.9707, AUC: 0.9948, F1: 0.9798
Val   - Loss: 0.0972, Acc: 0.9615, AUC: 0.9927, F1: 0.9736
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 14/15
Train - Loss: 0.0763, Acc: 0.9701, AUC: 0.9949, F1: 0.9794
Val   - Loss: 0.1066, Acc: 0.9563, AUC: 0.9919, F1: 0.9699
Epoch 15/15
Train - Loss: 0.0680, Acc: 0.9745, AUC: 0.9963, F1: 0.9824
Val   - Loss: 0.0964, Acc: 0.9654, AUC: 0.9929, F1: 0.9761
Final model saved to ./models/panda/attention/model_attention.pth
Model loaded successfully from ./models/panda/attention/model.pth
  ax.set_xticklabels([''] + ["Negative", "Positive"])
/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:65: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels([''] + ["Negative", "Positive"])
Confusion matrix saved at output/attention/confusion_matrix.png

--- Evaluation Results ---
Optimal Threshold: 0.7740
Accuracy: 0.9521, AUC: 0.9898
Precision: 0.9871, Recall: 0.9460, F1-Score: 0.9661
Confusion Matrix:
[[ 481   16]
 [  70 1227]]
Attention heatmap 0 saved at output/attention/attention_heatmap_0.png
Attention heatmap 1 saved at output/attention/attention_heatmap_1.png
Attention heatmap 2 saved at output/attention/attention_heatmap_2.png
Attention heatmap 3 saved at output/attention/attention_heatmap_3.png
Attention heatmap 4 saved at output/attention/attention_heatmap_4.png
