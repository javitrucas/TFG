panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|██████████| 8822/8822 [01:41<00:00, 87.18it/s]
[WSIDataset] Building data dict: 100%|██████████| 1794/1794 [00:18<00:00, 98.18it/s] 
[WSIDataset] Skipped 5 bags
[WSIDataset] Found 8817 already processed bags
panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|█████████▉| 1792/1794 [00:18<00:00, 98.12it/s] 
[WSIDataset] Skipped 0 bags
[WSIDataset] Found 1794 already processed bags
Epoch 1/15
Train - Loss: 0.2078, Acc: 0.9213, AUC: 0.9698, F1: 0.9460
Val   - Loss: 0.1627, Acc: 0.9371, AUC: 0.9835, F1: 0.9575
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 2/15
Train - Loss: 0.1819, Acc: 0.9332, AUC: 0.9783, F1: 0.9541
Val   - Loss: 0.1794, Acc: 0.9416, AUC: 0.9837, F1: 0.9599
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 3/15
Train - Loss: 0.1736, Acc: 0.9358, AUC: 0.9811, F1: 0.9558
Val   - Loss: 0.1602, Acc: 0.9342, AUC: 0.9846, F1: 0.9537
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 4/15
Train - Loss: 0.1772, Acc: 0.9406, AUC: 0.9805, F1: 0.9591
Val   - Loss: 0.1492, Acc: 0.9359, AUC: 0.9885, F1: 0.9569
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 5/15
Train - Loss: 0.1854, Acc: 0.9402, AUC: 0.9805, F1: 0.9588
Val   - Loss: 0.1735, Acc: 0.9450, AUC: 0.9847, F1: 0.9626
Epoch 6/15
Train - Loss: 0.1817, Acc: 0.9434, AUC: 0.9811, F1: 0.9611
Val   - Loss: 0.1767, Acc: 0.9269, AUC: 0.9853, F1: 0.9511
Epoch 7/15
Train - Loss: 0.1834, Acc: 0.9403, AUC: 0.9818, F1: 0.9589
Val   - Loss: 0.1618, Acc: 0.9433, AUC: 0.9854, F1: 0.9608
Epoch 8/15
Train - Loss: 0.1834, Acc: 0.9414, AUC: 0.9810, F1: 0.9597
Val   - Loss: 0.2155, Acc: 0.9246, AUC: 0.9876, F1: 0.9503
Epoch 9/15
Train - Loss: 0.1762, Acc: 0.9460, AUC: 0.9836, F1: 0.9628
Val   - Loss: 0.2090, Acc: 0.9365, AUC: 0.9897, F1: 0.9547
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 10/15
Train - Loss: 0.1867, Acc: 0.9434, AUC: 0.9832, F1: 0.9611
Val   - Loss: 0.1807, Acc: 0.9382, AUC: 0.9855, F1: 0.9586
Epoch 11/15
Train - Loss: 0.1811, Acc: 0.9441, AUC: 0.9835, F1: 0.9616
Val   - Loss: 0.1715, Acc: 0.9518, AUC: 0.9885, F1: 0.9664
Epoch 12/15
Train - Loss: 0.1797, Acc: 0.9480, AUC: 0.9828, F1: 0.9642
Val   - Loss: 0.2335, Acc: 0.9337, AUC: 0.9848, F1: 0.9556
Epoch 13/15
Train - Loss: 0.1857, Acc: 0.9451, AUC: 0.9827, F1: 0.9623
Val   - Loss: 0.1486, Acc: 0.9535, AUC: 0.9912, F1: 0.9675
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 14/15
Train - Loss: 0.1777, Acc: 0.9451, AUC: 0.9841, F1: 0.9623
Val   - Loss: 0.8433, Acc: 0.8197, AUC: 0.9902, F1: 0.8899
Epoch 15/15
Train - Loss: 0.1946, Acc: 0.9426, AUC: 0.9832, F1: 0.9606
Val   - Loss: 0.1618, Acc: 0.9512, AUC: 0.9902, F1: 0.9663
Model loaded successfully from ./models/panda/attention/model.pth
  ax.set_xticklabels([''] + ["Negative", "Positive"])
/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:65: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels([''] + ["Negative", "Positive"])
Confusion matrix saved at output/attention/confusion_matrix.png

--- Evaluation Results ---
Optimal Threshold: 0.8137
Accuracy: 0.9537, AUC: 0.9888
Precision: 0.9887, Recall: 0.9468, F1-Score: 0.9673
Confusion Matrix:
[[ 483   14]
 [  69 1228]]
Attention heatmap 0 saved at output/attention/attention_heatmap_0.png
Attention heatmap 1 saved at output/attention/attention_heatmap_1.png
Attention heatmap 2 saved at output/attention/attention_heatmap_2.png
Attention heatmap 3 saved at output/attention/attention_heatmap_3.png
Attention heatmap 4 saved at output/attention/attention_heatmap_4.png
