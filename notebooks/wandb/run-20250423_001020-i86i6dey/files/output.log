panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|██████████| 8822/8822 [01:44<00:00, 84.07it/s]
[WSIDataset] Building data dict: 100%|██████████| 1794/1794 [00:19<00:00, 93.03it/s] 
[WSIDataset] Skipped 5 bags
[WSIDataset] Found 8817 already processed bags
panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|█████████▉| 1788/1794 [00:19<00:00, 91.75it/s]
[WSIDataset] Skipped 0 bags
[WSIDataset] Found 1794 already processed bags
Epoch 1/15
Train - Loss: 0.1697, Acc: 0.9281, AUC: 0.9772, F1: 0.9507
Val   - Loss: 0.1204, Acc: 0.9529, AUC: 0.9882, F1: 0.9675
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 2/15
Train - Loss: 0.1333, Acc: 0.9465, AUC: 0.9852, F1: 0.9631
Val   - Loss: 0.1122, Acc: 0.9535, AUC: 0.9901, F1: 0.9679
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 3/15
Train - Loss: 0.1197, Acc: 0.9534, AUC: 0.9882, F1: 0.9678
Val   - Loss: 0.1155, Acc: 0.9512, AUC: 0.9907, F1: 0.9668
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 4/15
Train - Loss: 0.1106, Acc: 0.9566, AUC: 0.9895, F1: 0.9701
Val   - Loss: 0.1221, Acc: 0.9473, AUC: 0.9900, F1: 0.9642
Epoch 5/15
Train - Loss: 0.1063, Acc: 0.9599, AUC: 0.9903, F1: 0.9723
Val   - Loss: 0.1329, Acc: 0.9461, AUC: 0.9883, F1: 0.9631
Epoch 6/15
Train - Loss: 0.1019, Acc: 0.9606, AUC: 0.9911, F1: 0.9728
Val   - Loss: 0.1162, Acc: 0.9495, AUC: 0.9899, F1: 0.9654
Epoch 7/15
Train - Loss: 0.0970, Acc: 0.9623, AUC: 0.9919, F1: 0.9740
Val   - Loss: 0.1331, Acc: 0.9422, AUC: 0.9904, F1: 0.9611
Epoch 8/15
Train - Loss: 0.0932, Acc: 0.9643, AUC: 0.9924, F1: 0.9754
Val   - Loss: 0.1121, Acc: 0.9529, AUC: 0.9917, F1: 0.9680
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 9/15
Train - Loss: 0.0880, Acc: 0.9668, AUC: 0.9933, F1: 0.9771
Val   - Loss: 0.1170, Acc: 0.9541, AUC: 0.9905, F1: 0.9684
Epoch 10/15
Train - Loss: 0.0885, Acc: 0.9651, AUC: 0.9935, F1: 0.9760
Val   - Loss: 0.0980, Acc: 0.9620, AUC: 0.9923, F1: 0.9737
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 11/15
Train - Loss: 0.0823, Acc: 0.9688, AUC: 0.9942, F1: 0.9785
Val   - Loss: 0.1205, Acc: 0.9580, AUC: 0.9905, F1: 0.9710
Epoch 12/15
Train - Loss: 0.0805, Acc: 0.9692, AUC: 0.9945, F1: 0.9788
Val   - Loss: 0.1067, Acc: 0.9603, AUC: 0.9914, F1: 0.9726
Epoch 13/15
Train - Loss: 0.0786, Acc: 0.9711, AUC: 0.9947, F1: 0.9801
Val   - Loss: 0.1108, Acc: 0.9569, AUC: 0.9907, F1: 0.9702
Epoch 14/15
Train - Loss: 0.0759, Acc: 0.9719, AUC: 0.9946, F1: 0.9807
Val   - Loss: 0.1175, Acc: 0.9575, AUC: 0.9913, F1: 0.9705
Epoch 15/15
Train - Loss: 0.0715, Acc: 0.9741, AUC: 0.9954, F1: 0.9822
Val   - Loss: 0.1261, Acc: 0.9569, AUC: 0.9907, F1: 0.9706
Early stopping triggered.
Model loaded successfully from ./models/panda/attention/model.pth
  ax.set_xticklabels([''] + ["Negative", "Positive"])
/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:65: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels([''] + ["Negative", "Positive"])
Confusion matrix saved at output/attention/confusion_matrix.png

--- Evaluation Results ---
Optimal Threshold: 0.9288
Accuracy: 0.9504, AUC: 0.9882
Precision: 0.9855, Recall: 0.9453, F1-Score: 0.9650
Confusion Matrix:
[[ 479   18]
 [  71 1226]]
Attention heatmap 0 saved at output/attention/attention_heatmap_0.png
Attention heatmap 1 saved at output/attention/attention_heatmap_1.png
Attention heatmap 2 saved at output/attention/attention_heatmap_2.png
Attention heatmap 3 saved at output/attention/attention_heatmap_3.png
Attention heatmap 4 saved at output/attention/attention_heatmap_4.png
