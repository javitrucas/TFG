panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|██████████| 8822/8822 [09:26<00:00, 15.57it/s]
[WSIDataset] Building data dict: 100%|██████████| 1794/1794 [01:19<00:00, 22.50it/s]
[WSIDataset] Skipped 5 bags
[WSIDataset] Found 8817 already processed bags
panda
[WSIDataset] Scanning files...
[WSIDataset] Building data dict: 100%|█████████▉| 1792/1794 [01:19<00:00, 31.37it/s]
[WSIDataset] Skipped 0 bags
[WSIDataset] Found 1794 already processed bags
Epoch 1/15
Train - Loss: 0.2125, Acc: 0.9189, AUC: 0.9690, F1: 0.9443
Val   - Loss: 0.1887, Acc: 0.9388, AUC: 0.9886, F1: 0.9563
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 2/15
Train - Loss: 0.1921, Acc: 0.9300, AUC: 0.9750, F1: 0.9518
Val   - Loss: 0.1362, Acc: 0.9473, AUC: 0.9890, F1: 0.9629
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 3/15
Train - Loss: 0.1769, Acc: 0.9355, AUC: 0.9794, F1: 0.9556
Val   - Loss: 0.2952, Acc: 0.9189, AUC: 0.9822, F1: 0.9457
Epoch 4/15
Train - Loss: 0.1810, Acc: 0.9385, AUC: 0.9795, F1: 0.9577
Val   - Loss: 0.1172, Acc: 0.9501, AUC: 0.9902, F1: 0.9657
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 5/15
Train - Loss: 0.1889, Acc: 0.9365, AUC: 0.9791, F1: 0.9563
Val   - Loss: 0.1513, Acc: 0.9546, AUC: 0.9869, F1: 0.9683
Epoch 6/15
Train - Loss: 0.1721, Acc: 0.9399, AUC: 0.9824, F1: 0.9586
Val   - Loss: 0.1224, Acc: 0.9541, AUC: 0.9903, F1: 0.9682
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 7/15
Train - Loss: 0.1805, Acc: 0.9416, AUC: 0.9813, F1: 0.9599
Val   - Loss: 0.1503, Acc: 0.9541, AUC: 0.9888, F1: 0.9685
Epoch 8/15
Train - Loss: 0.1899, Acc: 0.9400, AUC: 0.9812, F1: 0.9588
Val   - Loss: 0.2973, Acc: 0.8963, AUC: 0.9831, F1: 0.9323
Epoch 9/15
Train - Loss: 0.1814, Acc: 0.9437, AUC: 0.9816, F1: 0.9612
Val   - Loss: 0.1858, Acc: 0.9444, AUC: 0.9893, F1: 0.9623
Epoch 10/15
Train - Loss: 0.1906, Acc: 0.9429, AUC: 0.9814, F1: 0.9607
Val   - Loss: 0.1151, Acc: 0.9592, AUC: 0.9910, F1: 0.9718
Final model saved to ./models/panda/attention/model_attention.pth
Epoch 11/15
Train - Loss: 0.1807, Acc: 0.9460, AUC: 0.9829, F1: 0.9629
Val   - Loss: 0.2229, Acc: 0.9240, AUC: 0.9878, F1: 0.9496
Epoch 12/15
Train - Loss: 0.1916, Acc: 0.9429, AUC: 0.9824, F1: 0.9607
Val   - Loss: 0.2240, Acc: 0.9320, AUC: 0.9871, F1: 0.9545
Epoch 13/15
Train - Loss: 0.1847, Acc: 0.9433, AUC: 0.9837, F1: 0.9610
Val   - Loss: 0.1589, Acc: 0.9495, AUC: 0.9900, F1: 0.9656
Epoch 14/15
Train - Loss: 0.1999, Acc: 0.9451, AUC: 0.9828, F1: 0.9623
Val   - Loss: 0.4484, Acc: 0.8849, AUC: 0.9866, F1: 0.9262
Epoch 15/15
Train - Loss: 0.1957, Acc: 0.9430, AUC: 0.9825, F1: 0.9608
Val   - Loss: 0.1227, Acc: 0.9529, AUC: 0.9904, F1: 0.9673
Early stopping triggered.
Model loaded successfully from ./models/panda/attention/model.pth
  ax.set_xticklabels([''] + ["Negative", "Positive"])
/home/javitrucas/TFG/scripts/medical_scripts/medical_evaluation.py:65: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels([''] + ["Negative", "Positive"])
Confusion matrix saved at output/attention/confusion_matrix.png

--- Evaluation Results ---
Optimal Threshold: 0.8652
Accuracy: 0.9504, AUC: 0.9890
Precision: 0.9895, Recall: 0.9414, F1-Score: 0.9648
Confusion Matrix:
[[ 484   13]
 [  76 1221]]
Attention heatmap 0 saved at output/attention/attention_heatmap_0.png
Attention heatmap 1 saved at output/attention/attention_heatmap_1.png
Attention heatmap 2 saved at output/attention/attention_heatmap_2.png
Attention heatmap 3 saved at output/attention/attention_heatmap_3.png
Attention heatmap 4 saved at output/attention/attention_heatmap_4.png
