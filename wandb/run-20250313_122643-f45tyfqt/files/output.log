=== Iniciando experimento con pooling_type=attention ===
rsna
[RSNADataset] Scanning files...
[RSNADataset] Found 1000 already processed bags
[RSNADataset] Number of bags found: 1000
rsna
[RSNADataset] Scanning files...
[RSNADataset] Found 150 already processed bags
[RSNADataset] Number of bags found: 150
Traceback (most recent call last):
  File "/home/javitrucas/TFG/scripts/medical_scripts/medical_main.py", line 88, in <module>
    trainer.train()
  File "/home/javitrucas/TFG/scripts/medical_scripts/medical_training.py", line 57, in train
    train_metrics = self._train_epoch(optimizer, criterion)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/TFG/scripts/medical_scripts/medical_training.py", line 116, in _train_epoch
    output, _ = self.model(bag_data, mask=mask)  # Ignorar attention_weights en entrenamiento
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/TFG/scripts/model.py", line 71, in forward
    bag_representation, attention_weights = self.attention(features, mask)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/TFG/scripts/model.py", line 33, in forward
    scores = self.attention(features).squeeze(-1)  # (batch, max_bag_size)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/javitrucas/miniconda3/envs/tfg/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: mat1 and mat2 shapes cannot be multiplied (40x512 and 128x64)
